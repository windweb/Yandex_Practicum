{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поиск токсичных комментариев\n",
    "\n",
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Обучим модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Построим модель со значением метрики качества *F1* не меньше 0.75. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Цели и задачи проекта\n",
    "\n",
    "**Цели:**\n",
    "\n",
    "Обучить модель классифицировать комментарии на позитивные и негативные.\n",
    "\n",
    "Модель позволит магазину искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "**Задачи:**\n",
    "1. Загрузим и подготовим данные.\n",
    "2. Обучим разные модели.\n",
    "3. Сделаем выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание данных\n",
    "\n",
    "В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Данные находятся в файле `/datasets/toxic_comments.csv`.\n",
    "\n",
    "Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Содержание\n",
    "\n",
    "1  [Подготовка](#1)\n",
    "\n",
    "*    1.1  [Очистка](#11)\n",
    "*    1.2  [Лемматизация *WordNetLemmatizer*](#12)\n",
    "*    1.3  [Лемматизация *WordNetLemmatizer + pos_tag*](#13)\n",
    "\n",
    "2  [Обучение](#2)\n",
    "\n",
    "*    2.1  [*LogisticRegression*](#21)\n",
    "*    2.2  [*DecisionTreeClassifier*](#22)\n",
    "*    2.3  [*LGBMClassifier*](#23)\n",
    "*    2.4  [Сравнение](#24)\n",
    "\n",
    "3  [Тестирование](#3)\n",
    "\n",
    "4  [Общий вывод](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score, train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:/Users/lorad/OneDrive/Documents/Моя папка/Data Science/Мои проекты/GitHubRepositories/'\n",
    "                 'YandexPracticum/11_ML_for_texts_search_for_toxic_comments/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158863</th>\n",
       "      <td>159022</td>\n",
       "      <td>My feeling is that it's a hoax — but that woul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109594</th>\n",
       "      <td>109691</td>\n",
       "      <td>\"\\nAs I suggested earlier, I brought this bloc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116378</th>\n",
       "      <td>116477</td>\n",
       "      <td>\"\\n\\n Your submission at Articles for creation...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119714</th>\n",
       "      <td>119819</td>\n",
       "      <td>Claus \\n\\nClaus is on all the maps but not men...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36174</th>\n",
       "      <td>36216</td>\n",
       "      <td>queer ur gay i hope u read this</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "158863      159022  My feeling is that it's a hoax — but that woul...      0\n",
       "109594      109691  \"\\nAs I suggested earlier, I brought this bloc...      0\n",
       "116378      116477  \"\\n\\n Your submission at Articles for creation...      0\n",
       "119714      119819  Claus \\n\\nClaus is on all the maps but not men...      0\n",
       "36174        36216                    queer ur gay i hope u read this      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159292.000000</td>\n",
       "      <td>159292.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>79725.697242</td>\n",
       "      <td>0.101612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>46028.837471</td>\n",
       "      <td>0.302139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39872.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>79721.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>119573.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>159450.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0          toxic\n",
       "count  159292.000000  159292.000000\n",
       "mean    79725.697242       0.101612\n",
       "std     46028.837471       0.302139\n",
       "min         0.000000       0.000000\n",
       "25%     39872.750000       0.000000\n",
       "50%     79721.500000       0.000000\n",
       "75%    119573.250000       0.000000\n",
       "max    159450.000000       1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**. \n",
    "\n",
    "В этом разделе были выполнены чтение и подготовка данных.\n",
    "\n",
    "В результате выполнения задач этого раздела было выявлено следующее:\n",
    "1. пропусков в данных нет;\n",
    "2. типы данных соответствуют требованиям для последующей очистки и лемматизации комментариев;\n",
    "3. целевой признак *toxic* имеет положительные значения для 10% комментариев (среднее значение *mean ~ 0.1*).\n",
    "\n",
    "Таким образом, данные подготовлены для очистки и лемматизации комментариев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"11\"></a>\n",
    "### Очистка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    \n",
    "    '''переводит в нижний регистр, оставляет только латиницу, удаляет stop_words'''\n",
    "    \n",
    "    stop_words = set(nltk_stopwords.words('english'))\n",
    "    text = text.lower()\n",
    "    word_list = re.sub(r\"[^a-z ]\", ' ', text).split()\n",
    "    word_notstop_list = [w for w in word_list if not w in stop_words]\n",
    "    return ' '.join(word_notstop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_text'] = data['text'].apply(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122519</th>\n",
       "      <td>122625</td>\n",
       "      <td>oi \\n\\nwhy did you give me a last warning, why...</td>\n",
       "      <td>1</td>\n",
       "      <td>oi give last warning cunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137363</th>\n",
       "      <td>137501</td>\n",
       "      <td>DryBones Palestine.jpg\\nwhat happend to the Pa...</td>\n",
       "      <td>0</td>\n",
       "      <td>drybones palestine jpg happend palestianian th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131623</th>\n",
       "      <td>131759</td>\n",
       "      <td>Keep it current \\n\\nWhen listing potential TNA...</td>\n",
       "      <td>0</td>\n",
       "      <td>keep current listing potential tna tc winners ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122233</th>\n",
       "      <td>122338</td>\n",
       "      <td>Silencing references through IP blocks? You're...</td>\n",
       "      <td>1</td>\n",
       "      <td>silencing references ip blocks seriously pathetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156762</th>\n",
       "      <td>156921</td>\n",
       "      <td>up\\n\\n  (Talk) \\n\\n  (Talk) \\n\\n  (Talk) \\n\\nB...</td>\n",
       "      <td>0</td>\n",
       "      <td>talk talk talk blocked blanking wikipedia arti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic  \\\n",
       "122519      122625  oi \\n\\nwhy did you give me a last warning, why...      1   \n",
       "137363      137501  DryBones Palestine.jpg\\nwhat happend to the Pa...      0   \n",
       "131623      131759  Keep it current \\n\\nWhen listing potential TNA...      0   \n",
       "122233      122338  Silencing references through IP blocks? You're...      1   \n",
       "156762      156921  up\\n\\n  (Talk) \\n\\n  (Talk) \\n\\n  (Talk) \\n\\nB...      0   \n",
       "\n",
       "                                               clean_text  \n",
       "122519                          oi give last warning cunt  \n",
       "137363  drybones palestine jpg happend palestianian th...  \n",
       "131623  keep current listing potential tna tc winners ...  \n",
       "122233  silencing references ip blocks seriously pathetic  \n",
       "156762  talk talk talk blocked blanking wikipedia arti...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"12\"></a>\n",
    "### Лемматизация *WordNetLemmatizer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm_text(text):\n",
    "    \n",
    "    '''Лемматизирует строку WordNetLemmatizer'''\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_list = text.split()\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "data['wnl_text'] = data['clean_text'].apply(lemm_text)\n",
    "data_lemm_time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print(data_lemm_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"13\"></a>\n",
    "### Лемматизация *WordNetLemmatizer + pos_tag*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postag_lemm_text(text):\n",
    "    \n",
    "    '''Лемматизирует строку WordNetLemmatizer с учетом nltk.pos_tag'''\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_list = text.split()\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in word_list])\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2270\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "data['wnlpostag_text'] = data['clean_text'].apply(postag_lemm_text)\n",
    "data_lemm_time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print(data_lemm_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>23053</th>\n",
       "      <th>51000</th>\n",
       "      <th>146121</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>23073</td>\n",
       "      <td>51056</td>\n",
       "      <td>146277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>And on another note, what right does he have t...</td>\n",
       "      <td>(UTC)\\n\\nI added to ODP link because it includ...</td>\n",
       "      <td>\"\\n\\n A Chelsea-persona page sounds excellent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean_text</th>\n",
       "      <td>another note right send blocking threats state...</td>\n",
       "      <td>utc added odp link includes links urban explor...</td>\n",
       "      <td>chelsea persona page sounds excellent much res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wnl_text</th>\n",
       "      <td>another note right send blocking threat state ...</td>\n",
       "      <td>utc added odp link includes link urban explora...</td>\n",
       "      <td>chelsea persona page sound excellent much resi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wnlpostag_text</th>\n",
       "      <td>another note right send block threat state poi...</td>\n",
       "      <td>utc add odp link include link urban exploratio...</td>\n",
       "      <td>chelsea persona page sound excellent much resi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           23053   \\\n",
       "Unnamed: 0                                                  23073   \n",
       "text            And on another note, what right does he have t...   \n",
       "toxic                                                           0   \n",
       "clean_text      another note right send blocking threats state...   \n",
       "wnl_text        another note right send blocking threat state ...   \n",
       "wnlpostag_text  another note right send block threat state poi...   \n",
       "\n",
       "                                                           51000   \\\n",
       "Unnamed: 0                                                  51056   \n",
       "text            (UTC)\\n\\nI added to ODP link because it includ...   \n",
       "toxic                                                           0   \n",
       "clean_text      utc added odp link includes links urban explor...   \n",
       "wnl_text        utc added odp link includes link urban explora...   \n",
       "wnlpostag_text  utc add odp link include link urban exploratio...   \n",
       "\n",
       "                                                           146121  \n",
       "Unnamed: 0                                                 146277  \n",
       "text            \"\\n\\n A Chelsea-persona page sounds excellent ...  \n",
       "toxic                                                           0  \n",
       "clean_text      chelsea persona page sounds excellent much res...  \n",
       "wnl_text        chelsea persona page sound excellent much resi...  \n",
       "wnlpostag_text  chelsea persona page sound excellent much resi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# промежуточно сохраняем файл с очищенными и лемматизированными комментариями\n",
    "'''\n",
    "data.to_csv('data_lemm2.csv', index=False)\n",
    "data = pd.read_csv('data_lemm2.csv')'''\n",
    "display(data.sample(3).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**. \n",
    "\n",
    "В этом разделе были выполнены следующие задачи:\n",
    "1. комментарии очищены: буквы переведены в нижний регистр, оставлена только латиница, удалены стоп-слова;\n",
    "2. комментарии лемматизированы без учёта части речи и с учётом части речи (POS-тегов).\n",
    "\n",
    "Таким образом, данные подготовлены для обучения моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, random_state=123, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data['wnl_text']\n",
    "corpus_2 = data['wnlpostag_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    corpus, \n",
    "    data['toxic'].values, \n",
    "    test_size=0.2, stratify=data['toxic'].values, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_2, features_test_2, target_train_2, target_test_2 = train_test_split(\n",
    "    corpus_2, \n",
    "    data['toxic'].values, \n",
    "    test_size=0.2, stratify=data['toxic'].values, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer()\n",
    "tf_idf_train = count_tf_idf.fit_transform(features_train)\n",
    "tf_idf_test = count_tf_idf.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf_2 = TfidfVectorizer()\n",
    "tf_idf_train_2 = count_tf_idf_2.fit_transform(features_train_2)\n",
    "tf_idf_test_2 = count_tf_idf_2.transform(features_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"21\"></a>\n",
    "### *LogisticRegression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.754 модель: LogisticRegression данные: wnl_text время работы модели: 6\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_1 = LogisticRegression(solver='liblinear', class_weight='balanced', random_state=123)\n",
    "\n",
    "model_1.mod = 'model_1'\n",
    "model_1.name = 'LogisticRegression'\n",
    "model_1.data = 'wnl_text'\n",
    "model_1.f1 = cross_val_score(model_1, tf_idf_train, target_train, cv=kfold, scoring='f1')\n",
    "model_1.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_1.f1.mean()), \n",
    "      'модель:', model_1.name, \n",
    "      'данные:', model_1.data, \n",
    "      'время работы модели:', model_1.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- f1: 0.754\n",
    "- модель: LogisticRegression \n",
    "- данные: wnl_text \n",
    "- время работы модели: 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.752 модель: LogisticRegression данные: wnlpostag_text время работы модели: 6\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_2 = LogisticRegression(solver='liblinear', class_weight='balanced', random_state=123)\n",
    "\n",
    "model_2.mod = 'model_2'\n",
    "model_2.name = 'LogisticRegression'\n",
    "model_2.data = 'wnlpostag_text'\n",
    "model_2.f1 = cross_val_score(model_2, tf_idf_train_2, target_train_2, cv=kfold, scoring='f1')\n",
    "\n",
    "model_2.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_2.f1.mean()), \n",
    "      'модель:', model_2.name, \n",
    "      'данные:', model_2.data, \n",
    "      'время работы модели:', model_2.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- f1: 0.752\n",
    "- модель: LogisticRegression \n",
    "- данные: wnlpostag_text \n",
    "- время работы модели: 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_validate\n",
    "\n",
    "# model_1 = LogisticRegression(solver='liblinear', class_weight='balanced', random_state=123)\n",
    "\n",
    "# model_1.mod = 'model_1'\n",
    "# model_1.name = 'LogisticRegression'\n",
    "# model_1.data = 'wnl_text'\n",
    "# model_1.f1 =  cross_validate(model_1, tf_idf_train, target_train, cv=kfold, scoring='f1')\n",
    "# model_1.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "# print('f1: %.3f' %(model_1.f1['test_score'].mean()), \n",
    "#       'модель:', model_1.name, \n",
    "#       'данные:', model_1.data, \n",
    "#       'время обучения fit_time: %.0f' %(model_1.f1['fit_time'].mean()),\n",
    "#       'время предсказания score_time: %.0f' %(model_1.f1['score_time'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f1: 0.754 модель: LogisticRegression данные: wnl_text время обучения fit_time: 1 время предсказания score_time: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"22\"></a>\n",
    "### *DecisionTreeClassifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.656 модель: DecisionTreeClassifier данные: wnl_text время работы модели: 554\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_3 = DecisionTreeClassifier(class_weight='balanced', random_state=123)\n",
    "\n",
    "model_3.mod = 'model_3'\n",
    "model_3.name = 'DecisionTreeClassifier'\n",
    "model_3.data = 'wnl_text'\n",
    "model_3.f1 = cross_val_score(model_3, tf_idf_train, target_train, cv=kfold, scoring='f1')\n",
    "\n",
    "model_3.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_3.f1.mean()), \n",
    "      'модель:', model_3.name, \n",
    "      'данные:', model_3.data, \n",
    "      'время работы модели:', model_3.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- f1: 0.656\n",
    "- модель: DecisionTreeClassifier \n",
    "- данные: wnl_text \n",
    "- время работы модели: 511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.659 модель: DecisionTreeClassifier данные: wnlpostag_text время работы модели: 446\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_4 = DecisionTreeClassifier(class_weight='balanced', random_state=123)\n",
    "\n",
    "model_4.mod = 'model_4'\n",
    "model_4.name = 'DecisionTreeClassifier'\n",
    "model_4.data = 'wnlpostag_text'\n",
    "model_4.f1 = cross_val_score(model_4, tf_idf_train_2, target_train_2, cv=kfold, scoring='f1')\n",
    "\n",
    "model_4.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_4.f1.mean()), \n",
    "      'модель:', model_4.name, \n",
    "      'данные:', model_4.data, \n",
    "      'время работы модели:', model_4.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- f1: 0.659\n",
    "- модель: DecisionTreeClassifier \n",
    "- данные: wnlpostag_text \n",
    "- время работы модели: 494"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"23\"></a>\n",
    "### *LGBMClassifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.723 модель: LGBMClassifier 50 данные: wnl_text время работы модели: 61\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_5 = LGBMClassifier(n_estimators=50, class_weight='balanced', boosting_type='gbdt', \n",
    "                         objective='binary', random_state=123)\n",
    "\n",
    "model_5.mod = 'model_5'\n",
    "model_5.name = 'LGBMClassifier 50'\n",
    "model_5.data = 'wnl_text'\n",
    "model_5.f1 = cross_val_score(model_5, tf_idf_train, target_train, cv=kfold, scoring='f1')\n",
    "\n",
    "model_5.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_5.f1.mean()), \n",
    "      'модель:', model_5.name, \n",
    "      'данные:', model_5.data, \n",
    "      'время работы модели:', model_5.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- f1: 0.723\n",
    "- модель: LGBMClassifier \n",
    "- n_estimators = 50\n",
    "- данные: wnl_text  \n",
    "- время работы модели: 74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.727 модель: LGBMClassifier 50 данные: wnlpostag_text время работы модели: 56\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_6 = LGBMClassifier(n_estimators=50, class_weight='balanced', boosting_type='gbdt', \n",
    "                         objective='binary', random_state=123)\n",
    "\n",
    "model_6.mod = 'model_6'\n",
    "model_6.name = 'LGBMClassifier 50'\n",
    "model_6.data = 'wnlpostag_text'\n",
    "model_6.f1 = cross_val_score(model_6, tf_idf_train_2, target_train_2, cv=kfold, scoring='f1')\n",
    "\n",
    "model_6.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_6.f1.mean()), \n",
    "      'модель:', model_6.name, \n",
    "      'данные:', model_6.data, \n",
    "      'время работы модели:', model_6.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- f1: 0.727\n",
    "- модель: LGBMClassifier \n",
    "- n_estimators = 50\n",
    "- данные: wnlpostag_text  \n",
    "- время работы модели: 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.764 модель: LGBMClassifier 500 данные: wnl_text время работы модели: 329\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_7 = LGBMClassifier(n_estimators=500, class_weight='balanced', boosting_type='gbdt', \n",
    "                         objective='binary', random_state=123)\n",
    "\n",
    "model_7.mod = 'model_7'\n",
    "model_7.name = 'LGBMClassifier 500'\n",
    "model_7.data = 'wnl_text'\n",
    "model_7.f1 = cross_val_score(model_7, tf_idf_train, target_train, cv=kfold, scoring='f1')\n",
    "\n",
    "model_7.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_7.f1.mean()), \n",
    "      'модель:', model_7.name, \n",
    "      'данные:', model_7.data, \n",
    "      'время работы модели:', model_7.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- f1: 0.764\n",
    "- модель: LGBMClassifier \n",
    "- n_estimators = 500\n",
    "- данные: wnl_text  \n",
    "- время работы модели: 358"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.727 модель: LGBMClassifier 500 данные: wnlpostag_text время работы модели: 55\n"
     ]
    }
   ],
   "source": [
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_8 = LGBMClassifier(n_estimators=500, class_weight='balanced', boosting_type='gbdt', \n",
    "                         objective='binary', random_state=123)\n",
    "\n",
    "model_8.mod = 'model_8'\n",
    "model_8.name = 'LGBMClassifier 500'\n",
    "model_8.data = 'wnlpostag_text'\n",
    "model_8.f1 = cross_val_score(model_5, tf_idf_train_2, target_train_2, cv=kfold, scoring='f1')\n",
    "\n",
    "model_8.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_8.f1.mean()), \n",
    "      'модель:', model_8.name, \n",
    "      'данные:', model_8.data, \n",
    "      'время работы модели:', model_8.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- f1: 0.727\n",
    "- модель: LGBMClassifier \n",
    "- n_estimators = 500\n",
    "- данные: wnlpostag_text  \n",
    "- время работы модели: 57"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"24\"></a>\n",
    "### Сравнение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [model_1, model_2, model_3, model_4, model_5, model_6, model_7, model_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a={}\n",
    "for i in model_list:\n",
    "    b={}    \n",
    "    b['model']=i.name\n",
    "    b['data']=i.data\n",
    "    b['f1_score']=i.f1.mean()\n",
    "    b['cross_val_time']=i.time\n",
    "    a[i.mod] = b\n",
    "\n",
    "final_table = pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>data</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>cross_val_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>wnl_text</td>\n",
       "      <td>0.753929</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>wnlpostag_text</td>\n",
       "      <td>0.752032</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>wnl_text</td>\n",
       "      <td>0.656351</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>wnlpostag_text</td>\n",
       "      <td>0.658628</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_5</th>\n",
       "      <td>LGBMClassifier 50</td>\n",
       "      <td>wnl_text</td>\n",
       "      <td>0.722983</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_6</th>\n",
       "      <td>LGBMClassifier 50</td>\n",
       "      <td>wnlpostag_text</td>\n",
       "      <td>0.726778</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_7</th>\n",
       "      <td>LGBMClassifier 500</td>\n",
       "      <td>wnl_text</td>\n",
       "      <td>0.763801</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_8</th>\n",
       "      <td>LGBMClassifier 500</td>\n",
       "      <td>wnlpostag_text</td>\n",
       "      <td>0.726778</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model            data  f1_score cross_val_time\n",
       "model_1      LogisticRegression        wnl_text  0.753929              6\n",
       "model_2      LogisticRegression  wnlpostag_text  0.752032              6\n",
       "model_3  DecisionTreeClassifier        wnl_text  0.656351            554\n",
       "model_4  DecisionTreeClassifier  wnlpostag_text  0.658628            446\n",
       "model_5       LGBMClassifier 50        wnl_text  0.722983             61\n",
       "model_6       LGBMClassifier 50  wnlpostag_text  0.726778             56\n",
       "model_7      LGBMClassifier 500        wnl_text  0.763801            329\n",
       "model_8      LGBMClassifier 500  wnlpostag_text  0.726778             55"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(final_table.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**. \n",
    "\n",
    "В этом разделе были выполнены следующие задачи:\n",
    "- обучены 8 моделей (*LogisticRegression*, *DecisionTreeClassifier* и *LGBMClassifier* с количеством деревьев 50 и 500) без учёта части речи и с учётом части речи (POS-тегов);\n",
    "\n",
    "В результате выполнения задач этого раздела было выявлено следующее:\n",
    "- в качестве лучшей модели (с наибольшим значением метрики *F1*) выбрана:\n",
    "   - *LGBMClassifier* на данных, лемматизированных без учета части речи, и с количеством деревьев n_estimators=500."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "## Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7722490759169746\n"
     ]
    }
   ],
   "source": [
    "model_7.fit(tf_idf_train, target_train)\n",
    "model_7.predicted = model_7.predict(tf_idf_test)\n",
    "model_7.test_f1 = f1_score(target_test, model_7.predicted)\n",
    "print(model_7.test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- f1: 0.772\n",
    "- модель: LGBMClassifier \n",
    "- n_estimators = 500\n",
    "- данные: wnl_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**. \n",
    "\n",
    "В этом разделе были выполнены следующие задачи:\n",
    "- протестирована лучшая модель:\n",
    "   - *LGBMClassifier* на данных, лемматизированных без учета части речи, и с количеством деревьев n_estimators=500.\n",
    "   \n",
    "В результате выполнения задач этого раздела было выявлено следующее:\n",
    "- в выбранной модели значение метрики качества *F1* превышает 0.75, как и изначально требовалось по условию задачи проекта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "## Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведено исследование с целью обучить модель классифицировать комментарии на позитивные и негативные.\n",
    "\n",
    "Входные данные - набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Результаты исследования позволят магазину искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "В результате исследования удалось получить следующие результаты **на обучающей выборке**:\n",
    "\n",
    "\n",
    "**1. Модель *LogisticRegression*:**\n",
    "\n",
    "   - данные, лемматизированые без учёта части речи (*wnl_text*):\n",
    "      - *F1* = 0.754\n",
    "      - время работы модели: 6 с\n",
    "\n",
    "\n",
    "   - данные, лемматизированые с учётом части речи - POS-тегов (*wnlpostag_text*):\n",
    "      - *F1* = 0.752\n",
    "      - время работы модели: 6 с\n",
    "\n",
    "\n",
    "**2. Модель *DecisionTreeClassifier*:**\n",
    "\n",
    "   - данные, лемматизированые без учёта части речи (*wnl_text*):\n",
    "      - *F1* = 0.656\n",
    "      - время работы модели: 511 с\n",
    "\n",
    "\n",
    "   - данные, лемматизированые с учётом части речи - POS-тегов (*wnlpostag_text*):\n",
    "      - *F1* = 0.659\n",
    "      - время работы модели: 494 с\n",
    "\n",
    "\n",
    "**3. Модель *LGBMClassifier*:**\n",
    "\n",
    "- количество деревьев *n_estimators* = 50:\n",
    "\n",
    "   - данные, лемматизированые без учёта части речи (*wnl_text*):\n",
    "      - *F1* = 0.723\n",
    "      - время работы модели: 74 с\n",
    "   - данные, лемматизированые с учётом части речи - POS-тегов (*wnlpostag_text*):\n",
    "      - *F1* = 0.727\n",
    "      - время работы модели: 61 с\n",
    "\n",
    "\n",
    "- количество деревьев *n_estimators* = 500:\n",
    "\n",
    "   - данные, лемматизированые без учёта части речи (*wnl_text*):\n",
    "      - *F1* = 0.764\n",
    "      - время работы модели: 358 с\n",
    "   - данные, лемматизированые с учётом части речи - POS-тегов (*wnlpostag_text*):\n",
    "      - *F1* = 0.727\n",
    "      - время работы модели: 57 с\n",
    "      \n",
    "      \n",
    "      \n",
    "Исходя из полученных результатов, можно сделать следующие **выводы**:\n",
    "\n",
    "\n",
    "1. В качестве лучшей модели (с наибольшим значением метрики *F1*) выбрана:\n",
    "   - *LGBMClassifier* на данных, лемматизированных без учета части речи (*wnl_text*), и с количеством деревьев *n_estimators*=500.\n",
    "   \n",
    "   \n",
    "2. Значение метрики *F1* = 0.772 для модели *LGBMClassifier* **на тестовой выборке**.\n",
    "   \n",
    "   \n",
    "3. В выбранной модели значение метрики качества *F1* превышает 0.75, как и изначально требовалось по условию задачи проекта.\n",
    "   \n",
    "   \n",
    "**Общие рекомендации:**\n",
    "\n",
    "Магазину можно рекомендовать использовать полученную модель ***LGBMClassifier*** в качестве инструмента, который будет искать токсичные комментарии и отправлять их на модерацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Чек-лист проверки**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2196,
    "start_time": "2023-01-26T21:17:43.084Z"
   },
   {
    "duration": 4049,
    "start_time": "2023-01-26T21:17:45.283Z"
   },
   {
    "duration": 37,
    "start_time": "2023-01-26T21:17:49.334Z"
   },
   {
    "duration": 43,
    "start_time": "2023-01-26T21:17:49.373Z"
   },
   {
    "duration": 29,
    "start_time": "2023-01-26T21:17:49.419Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-26T21:17:49.450Z"
   },
   {
    "duration": 24853,
    "start_time": "2023-01-26T21:17:49.456Z"
   },
   {
    "duration": 102,
    "start_time": "2023-01-26T21:18:14.311Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-26T21:18:14.414Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "260px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.375px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
